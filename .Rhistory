import tensorflow as tf;
from sklearn.preprocessing import MinMaxScaler;
import sys;
import MIDASpy as md
data_in = pd.read_csv("data/cces_jss_format.csv")
cont_vars = ["citylength_1","numchildren","birthyr"]
vals = data_in.nunique()
cat_vars = list(
data_in.columns[(vals.values > 2) & ~(data_in.columns.isin(cont_vars))]
)
bin_vars = list(data_in.columns[vals.values == 2])
data_bin = data_in[bin_vars].apply(md.binary_conv)
constructor_list = [data_in[cont_vars], data_bin]
data_cat = data_in[cat_vars]
data_oh, cat_col_list = md.cat_conv(data_cat)
constructor_list.append(data_oh)
data_0 = pd.concat(constructor_list, axis=1)
scaler = MinMaxScaler()
data_scaled = scaler.fit_transform(data_0)
data_scaled = pd.DataFrame(data_scaled, columns = data_0.columns)
na_loc = data_scaled.isnull()
data_scaled[na_loc] = np.nan
imputer = md.Midas(layer_structure= [256,256],
vae_layer = False,
seed= 89,
input_drop = 0.75)
imputer.build_model(data_scaled,
binary_columns = bin_vars,
softmax_columns =  cat_col_list)
imputer.train_model(training_epochs = 10)
imputations = imputer.generate_samples(m=10).output_list
for df in imputations:
df_unscaled = scaler.inverse_transform(df)
df_unscaled = pd.DataFrame(df_unscaled, columns = data_scaled.columns)
df["age"] = 2018 - df_unscaled["birthyr"]
df["CC18_415a"] = np.where(df_unscaled["CC18_415a"] >= 0.5,1,0)
model = md.combine(y_var = "CC18_415a",
X_vars = ["age"],
df_list = imputations)
model'
)
py_eval(code=
'import numpy as np;
import pandas as pd;
import tensorflow as tf;
from sklearn.preprocessing import MinMaxScaler;
import sys;
import MIDASpy as md
data_in = pd.read_csv("data/cces_jss_format.csv")
cont_vars = ["citylength_1","numchildren","birthyr"]
vals = data_in.nunique()
cat_vars = list(
data_in.columns[(vals.values > 2) & ~(data_in.columns.isin(cont_vars))]
)
bin_vars = list(data_in.columns[vals.values == 2])
data_bin = data_in[bin_vars].apply(md.binary_conv)
constructor_list = [data_in[cont_vars], data_bin]
data_cat = data_in[cat_vars]
data_oh, cat_col_list = md.cat_conv(data_cat)
constructor_list.append(data_oh)
data_0 = pd.concat(constructor_list, axis=1)
scaler = MinMaxScaler()
data_scaled = scaler.fit_transform(data_0)
data_scaled = pd.DataFrame(data_scaled, columns = data_0.columns)
na_loc = data_scaled.isnull()
data_scaled[na_loc] = np.nan
imputer = md.Midas(layer_structure= [256,256],
vae_layer = False,
seed= 89,
input_drop = 0.75)
imputer.build_model(data_scaled,
binary_columns = bin_vars,
softmax_columns =  cat_col_list)
imputer.train_model(training_epochs = 10)
imputations = imputer.generate_samples(m=10).output_list
for df in imputations:
df_unscaled = scaler.inverse_transform(df)
df_unscaled = pd.DataFrame(df_unscaled, columns = data_scaled.columns)
df["age"] = 2018 - df_unscaled["birthyr"]
df["CC18_415a"] = np.where(df_unscaled["CC18_415a"] >= 0.5,1,0)
model = md.combine(y_var = "CC18_415a",
X_vars = ["age"],
df_list = imputations)
model'
)
py("print('hello world')")
reticulate::py("print('hello world')")
py_run_string(
'import numpy as np;
import pandas as pd;
import tensorflow as tf;
from sklearn.preprocessing import MinMaxScaler;
import sys;
import MIDASpy as md;
data_in = pd.read_csv("data/cces_jss_format.csv");
cont_vars = ["citylength_1","numchildren","birthyr"];
vals = data_in.nunique();
cat_vars = list(
data_in.columns[(vals.values > 2) & ~(data_in.columns.isin(cont_vars))]
);
bin_vars = list(data_in.columns[vals.values == 2]);
data_bin = data_in[bin_vars].apply(md.binary_conv);
constructor_list = [data_in[cont_vars], data_bin];
data_cat = data_in[cat_vars];
data_oh, cat_col_list = md.cat_conv(data_cat);
constructor_list.append(data_oh);
data_0 = pd.concat(constructor_list, axis=1);
scaler = MinMaxScaler();
data_scaled = scaler.fit_transform(data_0);
data_scaled = pd.DataFrame(data_scaled, columns = data_0.columns);
na_loc = data_scaled.isnull();
data_scaled[na_loc] = np.nan;
imputer = md.Midas(layer_structure= [256,256],
vae_layer = False,
seed= 89,
input_drop = 0.75);
imputer.build_model(data_scaled,
binary_columns = bin_vars,
softmax_columns =  cat_col_list);
imputer.train_model(training_epochs = 10);
imputations = imputer.generate_samples(m=10).output_list;
for df in imputations:
df_unscaled = scaler.inverse_transform(df)
df_unscaled = pd.DataFrame(df_unscaled, columns = data_scaled.columns)
df["age"] = 2018 - df_unscaled["birthyr"]
df["CC18_415a"] = np.where(df_unscaled["CC18_415a"] >= 0.5,1,0);
model = md.combine(y_var = "CC18_415a",
X_vars = ["age"],
df_list = imputations);
model'
)
py_run_string("print('hellow world')")
py_run_string("print('hellow world')")
py_run_string(
"print('hello');
print('world')"
)
py_run_string(
"print('hello');
print('world')"
)
py_run_string(
"print('hello')
print('world')"
)
py_run_string(
"print('hello')
print('world')
for i in range(0,10):
print(i)"
)
py_run_string(
'import numpy as np
import pandas as pd
import tensorflow as tf
from sklearn.preprocessing import MinMaxScaler
import sys
import MIDASpy as md
data_in = pd.read_csv("data/cces_jss_format.csv")
cont_vars = ["citylength_1","numchildren","birthyr"]
vals = data_in.nunique()
cat_vars = list(
data_in.columns[(vals.values > 2) & ~(data_in.columns.isin(cont_vars))]
)
bin_vars = list(data_in.columns[vals.values == 2])
data_bin = data_in[bin_vars].apply(md.binary_conv)
constructor_list = [data_in[cont_vars], data_bin]
data_cat = data_in[cat_vars]
data_oh, cat_col_list = md.cat_conv(data_cat)
constructor_list.append(data_oh)
data_0 = pd.concat(constructor_list, axis=1)
scaler = MinMaxScaler()
data_scaled = scaler.fit_transform(data_0)
data_scaled = pd.DataFrame(data_scaled, columns = data_0.columns)
na_loc = data_scaled.isnull()
data_scaled[na_loc] = np.nan
imputer = md.Midas(layer_structure= [256,256],
vae_layer = False,
seed= 89,
input_drop = 0.75)
imputer.build_model(data_scaled,
binary_columns = bin_vars,
softmax_columns =  cat_col_list)
imputer.train_model(training_epochs = 10)
imputations = imputer.generate_samples(m=10).output_list
for df in imputations:
df_unscaled = scaler.inverse_transform(df)
df_unscaled = pd.DataFrame(df_unscaled, columns = data_scaled.columns)
df["age"] = 2018 - df_unscaled["birthyr"]
df["CC18_415a"] = np.where(df_unscaled["CC18_415a"] >= 0.5,1,0)
model = md.combine(y_var = "CC18_415a",
X_vars = ["age"],
df_list = imputations)
model'
)
Sys.time()
py(model)
reticulate::py_call(model)
reticulate::py_call("model")
py_run_string("print(model)")
py_run_string("model")
py_run_string('print(model)')
?r_to_py
set.seed(89)
## Read data for analysis
cat_vars <- c("CC18_401","CC18_413d","educ","race","marstat","votereg","OScode","CompRating",
"region","pid7","immstat","employ","sexuality","trans","industryclass","pew_churatd")
bin_vars <- c("CC18_415a","CC18_417_a","gender")
cont_vars <- c("citylength_1","numchildren","birthyr")
data_0_test <- fread("data/cces_jss_format.csv", select = c(cat_vars, bin_vars, cont_vars))
r_to_py(data_0_test)
py_run_string("print(data_0_test")
py_run_string("print(data_0_test)")
py_load_object(data_0_test)
py$data_0_test <- data_0_test
py_run_string("print(data_0_test")
py_run_string("print(data_0_test)")
cces <- read_csv("../linux/JSS/replication_materials/data/cces_jss_format.csv")
library(tidyverse)
cces <- read_csv("../linux/JSS/replication_materials/data/cces_jss_format.csv")
print(object.size(cces), "Mb")
print(object.size(cces),units =  "Mb")
library(devtools)
check()
check_rhub()
build()
# Imputation workflow
library("rMIDAS")
install.packages("rMIDAS")
library(rMIDAS)
version(rMIDAS)
data(quakes)
force(quakes)
data(airquality)
x_conv <- convert(add_missingness(quakes, prop=0.1),
minmax_scale = TRUE)
x_train <- train(x_conv,
training_epochs = 20,
layer_structure = c(128,128),
input_drop = 0.75,
seed = 89)
force(airquality)
x_complete <- complete(x_train, m = 1)
?complete
complete2 <- function(mid_obj,
m=10L,
unscale = TRUE,
bin_label = TRUE,
cat_coalesce = TRUE,
fast = FALSE,
file = NULL,
file_root = NULL) {
if (!inherits(mid_obj,"midas_base.Midas")) {
stop("Trained midas object not supplied to 'mid_obj' argument")
}
if (is.null(options("python_initialised")$python_initialised)) {
python_init()
}
if (!("preproc" %in% names(mid_obj))) {
unscale = FALSE
bin_label = FALSE
cat_coalesce = FALSE
}
draws <- mid_obj$generate_samples(m = as.integer(m))$output_list
if ((unscale || bin_label || cat_coalesce)) {
message("Imputations generated. Completing post-imputation transformations.\n")
}
## Reverse pre-processing steps from convert():
draws_post <- lapply(draws, function(df) {
df <- as.data.table(df)
# Undo scaling
if (unscale) {
num_params <- mid_obj$preproc$minmax_params
num_cols <- names(num_params)
for (j in num_cols) {
set(df, j = j, value = undo_minmax(df[[j]], s_min = num_params[[j]]$min, s_max = num_params[[j]]$max))
}
}
# Add binary labels
if (bin_label) {
bin_params <- mid_obj$preproc$bin_list
bin_cols <- names(bin_params)
for (j in bin_cols) {
set(df, j = j, value = add_bin_labels(df[[j]],
one = bin_params[[j]][1],
zero = bin_params[[j]][2],
fast))
}
}
if (cat_coalesce) {
cat_params <- mid_obj$preproc$cat_lists
cat_cols <- mid_obj$preproc$cat_names
for (i in 1:length(cat_cols)) {
set(df,
j = cat_cols[[i]],
value = coalesce_one_hot(X = df[,cat_params[[i]], with = FALSE],
var_name = cat_cols[i],
fast))
}
# Remove one-hot columns
df[,do.call("c",cat_params)] <- NULL
}
return(as.data.frame(df))
})
# --- Save files
if (!is.null(file)) {
message("Saving imputed datasets.\n")
if (is.null(file_root)) {
file_root <- paste0("midas_impute_",format(Sys.time(), "%y%m%d_%H%M%S"))
}
sapply(1:m, function (y) data.table::fwrite(x=draws_post[[y]], file = paste0(file,"/",file_root,"_",y,".csv")))
}
return(draws_post)
}
x_complete <- complete2(x_train, m = 1)
x_train$preproc$cat_names
length(x_train$preproc$cat_names)
1:0
x_train$preproc$cat_lists
is.null(x_train$preproc$cat_lists)
exists(x_train$preproc$cat_lists)
is.null(x_train$preproc$cat_lists)
!is.null(mid_obj$preproc$cat_lists)
!is.null(x_train$preproc$cat_lists)
complete2 <- function(mid_obj,
m=10L,
unscale = TRUE,
bin_label = TRUE,
cat_coalesce = TRUE,
fast = FALSE,
file = NULL,
file_root = NULL) {
if (!inherits(mid_obj,"midas_base.Midas")) {
stop("Trained midas object not supplied to 'mid_obj' argument")
}
if (is.null(options("python_initialised")$python_initialised)) {
python_init()
}
if (!("preproc" %in% names(mid_obj))) {
unscale = FALSE
bin_label = FALSE
cat_coalesce = FALSE
}
draws <- mid_obj$generate_samples(m = as.integer(m))$output_list
if ((unscale || bin_label || cat_coalesce)) {
message("Imputations generated. Completing post-imputation transformations.\n")
}
## Reverse pre-processing steps from convert():
draws_post <- lapply(draws, function(df) {
df <- as.data.table(df)
# Undo scaling
if (unscale) {
num_params <- mid_obj$preproc$minmax_params
num_cols <- names(num_params)
for (j in num_cols) {
set(df, j = j, value = undo_minmax(df[[j]], s_min = num_params[[j]]$min, s_max = num_params[[j]]$max))
}
}
# Add binary labels
if (bin_label) {
bin_params <- mid_obj$preproc$bin_list
bin_cols <- names(bin_params)
for (j in bin_cols) {
set(df, j = j, value = add_bin_labels(df[[j]],
one = bin_params[[j]][1],
zero = bin_params[[j]][2],
fast))
}
}
if (cat_coalesce & !is.null(mid_obj$preproc$cat_lists)) {
cat_params <- mid_obj$preproc$cat_lists
cat_cols <- mid_obj$preproc$cat_names
for (i in 1:length(cat_cols)) {
set(df,
j = cat_cols[[i]],
value = coalesce_one_hot(X = df[,cat_params[[i]], with = FALSE],
var_name = cat_cols[i],
fast))
}
# Remove one-hot columns
df[,do.call("c",cat_params)] <- NULL
}
return(as.data.frame(df))
})
# --- Save files
if (!is.null(file)) {
message("Saving imputed datasets.\n")
if (is.null(file_root)) {
file_root <- paste0("midas_impute_",format(Sys.time(), "%y%m%d_%H%M%S"))
}
sapply(1:m, function (y) data.table::fwrite(x=draws_post[[y]], file = paste0(file,"/",file_root,"_",y,".csv")))
}
return(draws_post)
}
x_complete <- complete2(x_train, m = 1)
View(x_complete[[1]])
x_complete <- complete2(x_train, m = 3)
head(quakes)
x_train$preproc$bin_list
names(x_train$preproc$bin_list)
for (i in names(x_train$preproc$bin_list)) {print("hello")}
complete2 <- function(mid_obj,
m=10L,
unscale = TRUE,
bin_label = TRUE,
cat_coalesce = TRUE,
fast = FALSE,
file = NULL,
file_root = NULL) {
if (!inherits(mid_obj,"midas_base.Midas")) {
stop("Trained midas object not supplied to 'mid_obj' argument")
}
if (is.null(options("python_initialised")$python_initialised)) {
python_init()
}
if (!("preproc" %in% names(mid_obj))) {
unscale = FALSE
bin_label = FALSE
cat_coalesce = FALSE
}
draws <- mid_obj$generate_samples(m = as.integer(m))$output_list
if ((unscale || bin_label || cat_coalesce)) {
message("Imputations generated. Completing post-imputation transformations.\n")
}
## Reverse pre-processing steps from convert():
draws_post <- lapply(draws, function(df) {
df <- as.data.table(df)
# Undo scaling
if (unscale) {
num_params <- mid_obj$preproc$minmax_params
num_cols <- names(num_params)
for (j in num_cols) {
set(df, j = j, value = undo_minmax(df[[j]], s_min = num_params[[j]]$min, s_max = num_params[[j]]$max))
}
}
# Add binary labels
if (bin_label) {
bin_params <- mid_obj$preproc$bin_list
bin_cols <- names(bin_params)
for (j in bin_cols) {
set(df, j = j, value = add_bin_labels(df[[j]],
one = bin_params[[j]][1],
zero = bin_params[[j]][2],
fast))
}
}
cat_params <- mid_obj$preproc$cat_lists
if (cat_coalesce & !is.null(cat_params)) {
cat_cols <- mid_obj$preproc$cat_names
for (i in 1:length(cat_cols)) {
set(df,
j = cat_cols[[i]],
value = coalesce_one_hot(X = df[,cat_params[[i]], with = FALSE],
var_name = cat_cols[i],
fast))
}
# Remove one-hot columns
df[,do.call("c",cat_params)] <- NULL
}
return(as.data.frame(df))
})
# --- Save files
if (!is.null(file)) {
message("Saving imputed datasets.\n")
if (is.null(file_root)) {
file_root <- paste0("midas_impute_",format(Sys.time(), "%y%m%d_%H%M%S"))
}
sapply(1:m, function (y) data.table::fwrite(x=draws_post[[y]], file = paste0(file,"/",file_root,"_",y,".csv")))
}
return(draws_post)
}
x_complete <- complete2(x_train, m = 3)
x_complete <- complete2(x_train, m = 5)
x_complete <- complete2(x_train, m = 5)
x_complete <- complete2(x_train, m = 5)
x_conv <- convert(add_missingness(airquality, prop=0.1),
minmax_scale = TRUE)
x_train <- train(x_conv,
training_epochs = 20,
layer_structure = c(128,128),
input_drop = 0.75,
seed = 89)
x_complete <- complete2(x_train, m = 5)
airquality
head(airquality)
x_conv <- convert(add_missingness(airquality, prop=0.1),
minmax_scale = TRUE)
x_train <- train(x_conv,
training_epochs = 20,
layer_structure = c(128,128),
input_drop = 0.75,
seed = 89)
x_complete <- complete2(x_train, m = 5)
rm(complete2)
detach("package:rMIDAS", unload = TRUE)
library(devtools)
install.packages("devtools")
library(devtools)
load_all()
??rMIDAS
data(quakes)
data(airquality)
x_conv <- convert(add_missingness(airquality, prop=0.1),
minmax_scale = TRUE)
x_train <- train(x_conv,
training_epochs = 20,
layer_structure = c(128,128),
input_drop = 0.75,
seed = 89)
mid_py_setup()
reticulate::py_available()
reticulate::py_config()
